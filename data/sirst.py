import torch

import torch.utils.data as Data
import torchvision.transforms as transforms

import cv2
import os
import os.path as osp
import shutil
import re
from pathlib import Path

from data.utils import RandomResize, Augment_transform, mask2point


__all__ = ["SirstAugDataset", "IRSTD1kDataset", "NUDTDataset"]


class IRSTD1kDataset(Data.Dataset):
    """
    Return: Single channel
    """

    def __init__(
        self,
        base_dir=r"W:/DataSets/Infraid_datasets/IRSTD-1k",
        mode="train",
        base_size=256,
        pt_label=False,
        offset = 0,
        pseudo_label=False,
        preded_label=False,
        augment=True,
        turn_num='',
        target_mix = False,
        file_name = ''
    ):
        assert mode in ["train", "test"]

        if mode == "train":
            self.data_dir = osp.join(base_dir, "trainval")
        elif mode == "test":
            self.data_dir = osp.join(base_dir, "test")
        else:
            raise NotImplementedError
        
        self.mode = mode
        self.base_size = base_size
        self.pt_label = pt_label
        self.offset = offset
        self.pesudo_label = pseudo_label
        self.preded_label = preded_label
        self.aug = augment
        self.turn_num = turn_num
        self.target_mix = target_mix
        self.names = []
        for filename in os.listdir(osp.join(self.data_dir, 'images' + file_name)):
            if filename.endswith("png"):
                self.names.append(filename)

        self.aug_transformer = Augment_transform(base_size, mode) if augment else Augment_transform(base_size, "test")
        # self.gaussian_blur = transforms.GaussianBlur(kernel_size=5, sigma=(0.8, 1.0)) if target_mix else None
        # self.target_trans = transforms.Compose([
        #     transforms.RandomAffine(degrees=180, translate=(0.3, 0.3)),
        #     transforms.RandomHorizontalFlip()])  # éšæœºæ°´å¹³ç¿»è½¬
        # self.gaussian_filter3 = transforms.GaussianBlur(kernel_size=3, sigma=(0.3, 0.5)) if target_mix else None
        # self.gaussian_filter9 = transforms.GaussianBlur(kernel_size=9, sigma=(0.3, 0.5)) if target_mix else None

    def __getitem__(self, i):
        name = self.names[i]
        img_path = osp.join(self.data_dir, "images", name)
        pesudo_label_path = osp.join(self.data_dir, f'pixel_pseudo_label{self.turn_num}', name)
        preded_label_path = osp.join(self.data_dir, f'preded_label/{self.turn_num}', name)
        label_path = osp.join(self.data_dir, "masks", name)

        img, mask= cv2.imread(img_path, 0), cv2.imread(label_path, 0)
        img, mask= torch.from_numpy(img).unsqueeze(0).float(), torch.from_numpy(mask).unsqueeze(0).float()
        
        if self.pesudo_label:
            pesudo_label = cv2.imread(pesudo_label_path, 0)
            pesudo_label = torch.from_numpy(pesudo_label).unsqueeze(0).float()
            mask = torch.cat([mask, pesudo_label], dim=0)
        if self.preded_label:
            preded_label = cv2.imread(preded_label_path, 0)
            preded_label = torch.from_numpy(preded_label).unsqueeze(0).float()
            mask = torch.cat([mask, preded_label], dim=0)
        
        img, mask = self.aug_transformer(img, mask)

        img, mask = img / 255.0, mask / 255.0

        if self.pt_label:
            pt_label = mask2point(mask[0].unsqueeze(0), img, self.offset)
            mask[0] = pt_label

        return img, mask

    def __len__(self):
        return len(self.names)


class NUDTDataset(Data.Dataset):
    """
    Return: Single channel
    """
    def __init__(
        self,
        base_dir=r"W:/DataSets/Infraid_datasets/NUDT-SIRST",
        mode="train",
        base_size=256,
        pt_label=False,
        offset = 0,
        pseudo_label=False,
        preded_label=False,
        augment=True,
        turn_num='',
        target_mix = False,
        file_name = ''
    ):
        assert mode in ["train", "test"]

        if mode == "train":
            self.data_dir = osp.join(base_dir, "trainval")
        elif mode == "test":
            self.data_dir = osp.join(base_dir, "test")
        else:
            raise NotImplementedError
        self.mode = mode 
        self.base_size = base_size
        self.pt_label = pt_label
        self.offset = offset
        self.pesudo_label = pseudo_label
        self.preded_label = preded_label
        self.aug = augment
        self.turn_num = turn_num
        self.target_mix = target_mix
        self.names = []
        for filename in os.listdir(osp.join(self.data_dir, 'images' + file_name)):
            if filename.endswith("png"):
                self.names.append(filename)

        self.aug_transformer = Augment_transform(base_size, mode) if augment else Augment_transform(base_size, "test")
        # self.gaussian_blur = transforms.GaussianBlur(kernel_size=5, sigma=(0.8, 1.0)) if target_mix else None
        # self.target_trans = transforms.Compose([
        #     transforms.RandomAffine(degrees=180, translate=(0.3, 0.3)),
        #     transforms.RandomHorizontalFlip()])  # éšæœºæ°´å¹³ç¿»è½¬
        # self.gaussian_filter3 = transforms.GaussianBlur(kernel_size=3, sigma=(0.3, 0.5)) if target_mix else None
        # self.gaussian_filter9 = transforms.GaussianBlur(kernel_size=9, sigma=(0.3, 0.5)) if target_mix else None

    def __getitem__(self, i):
        name = self.names[i]
        img_path = osp.join(self.data_dir, "images", name)
        pesudo_label_path = osp.join(self.data_dir, f'pixel_pseudo_label{self.turn_num}', name)
        preded_label_path = osp.join(self.data_dir, f'preded_label/{self.turn_num}', name)
        label_path = osp.join(self.data_dir, "masks", name)

        img, mask= cv2.imread(img_path, 0), cv2.imread(label_path, 0)
        img, mask= torch.from_numpy(img).unsqueeze(0).float(), torch.from_numpy(mask).unsqueeze(0).float()
        
        if self.pesudo_label:
            pesudo_label = cv2.imread(pesudo_label_path, 0)
            pesudo_label = torch.from_numpy(pesudo_label).unsqueeze(0).float()
            mask = torch.cat([mask, pesudo_label], dim=0)
        if self.preded_label:
            preded_label = cv2.imread(preded_label_path, 0)
            preded_label = torch.from_numpy(preded_label).unsqueeze(0).float()
            mask = torch.cat([mask, preded_label], dim=0)
        
        img, mask = self.aug_transformer(img, mask)

        img, mask = img / 255.0, mask / 255.0

        if self.pt_label:
            pt_label = mask2point(mask[0].unsqueeze(0), img, self.offset)
            mask[0] = pt_label

        return img, mask
    
    def __len__(self):
        return len(self.names)
    

# class SirstAugDataset(Data.Dataset):
#     '''
#     Return: Single channel
#     '''
#     def __init__(self, base_dir=r'/Users/tianfangzhang/Program/DATASETS/sirst_aug',
#                  mode='train', base_size=256):
#         assert mode in ['train', 'test']

#         if mode == 'train':
#             self.data_dir = osp.join(base_dir, 'trainval')
#         elif mode == 'test':
#             self.data_dir = osp.join(base_dir, 'test')
#         else:
#             raise NotImplementedError

#         self.base_size = base_size

#         self.names = []
#         for filename in os.listdir(osp.join(self.data_dir, 'images')):
#             if filename.endswith('png'):
#                 self.names.append(filename)
#         self.tranform = augumentation()
#         # self.transform = transforms.Compose([
#         #     transforms.ToTensor(),
#         #     transforms.Normalize([.485, .456, .406], [.229, .224, .225]),  # Default mean and std
#         # ])

#     def __getitem__(self, i):
#         name = self.names[i]
#         img_path = osp.join(self.data_dir, 'images', name)
#         label_path = osp.join(self.data_dir, 'masks', name)

#         img, mask = cv2.imread(img_path, 0), cv2.imread(label_path, 0)
#         img, mask = self.tranform(img, mask)
#         img = img.reshape(1, self.base_size, self.base_size) / 255.
#         if np.max(mask) > 0:
#             mask = mask.reshape(1, self.base_size, self.base_size) / np.max(mask)
#         else:
#             mask = mask.reshape(1, self.base_size, self.base_size)
#         # row, col = img.shape
#         # img = img.reshape(1, row, col) / 255.
#         # if np.max(mask) > 0:
#         #     mask = mask.reshape(1, row, col) / np.max(mask)
#         # else:
#         #     mask = mask.reshape(1, row, col)

#         img = torch.from_numpy(img).type(torch.FloatTensor)
#         mask = torch.from_numpy(mask).type(torch.FloatTensor)
#         return img, mask

#     def __len__(self):
#         return len(self.names)


class MDFADataset(Data.Dataset):
    '''
    Return: Single channel
    '''
    def __init__(
        self,
        base_dir=r"W:/DataSets/Infraid_datasets/NUDT-SIRST",
        mode="train",
        base_size=256,
        pt_label=False,
        offset = 0,
        pseudo_label=False,
        preded_label=False,
        augment=True,
        turn_num='',
        target_mix = False,
        file_name = '',
    ):
        assert mode in ["train", "test"]

        if mode == "train":
            self.data_dir = osp.join(base_dir, "trainval")
        elif mode == "test":
            self.data_dir = osp.join(base_dir, "test")
        else:
            raise NotImplementedError
        self.mode = mode 
        self.base_size = base_size
        self.pt_label = pt_label
        self.offset = offset
        self.pesudo_label = pseudo_label
        self.preded_label = preded_label
        self.aug = augment
        self.turn_num = turn_num
        self.target_mix = target_mix
        self.names = []
        for filename in os.listdir(osp.join(self.data_dir, 'images' + file_name)):
            if filename.endswith('png'):
                self.names.append(filename)

        self.aug_transformer = Augment_transform(base_size, mode) if augment else Augment_transform(base_size, "test")

    def __getitem__(self, i):
        name = self.names[i]
        img_path = osp.join(self.data_dir, "images", name)
        pesudo_label_path = osp.join(self.data_dir, f'pixel_pseudo_label{self.turn_num}', name)
        preded_label_path = osp.join(self.data_dir, f'preded_label/{self.turn_num}', name)
        label_path = osp.join(self.data_dir, "masks", name)

        img, mask= cv2.imread(img_path, 0), cv2.imread(label_path, 0)
        img, mask= torch.from_numpy(img).unsqueeze(0).float(), torch.from_numpy(mask).unsqueeze(0).float()
        
        if self.pesudo_label:
            pesudo_label = cv2.imread(pesudo_label_path, 0)
            pesudo_label = torch.from_numpy(pesudo_label).unsqueeze(0).float()
            pesudo_label = transforms.functional.resize(pesudo_label, (mask.shape[-2], mask.shape[-1]))
            mask = torch.cat([mask, pesudo_label], dim=0)
        if self.preded_label:
            preded_label = cv2.imread(preded_label_path, 0)
            preded_label = torch.from_numpy(preded_label).unsqueeze(0).float()
            mask = torch.cat([mask, preded_label], dim=0)
        
        img, mask = self.aug_transformer(img, mask)

        img, mask = img / 255.0, mask / 255.0

        if self.pt_label:
            pt_label = mask2point(mask[0].unsqueeze(0), img, self.offset)
            mask[0] = pt_label

        return img, mask
    
    def __len__(self):
        return len(self.names)


def __organize_dataset(training_dir, target_base_path):
    """
    æ•´ç†æ•°æ®é›†ï¼šå°† training_dir ä¸­ä»¥ _1 ç»“å°¾çš„æ–‡ä»¶ä½œä¸º imageï¼Œä»¥ _2 ç»“å°¾çš„æ–‡ä»¶ä½œä¸º maskï¼Œåˆ†åˆ«å¤åˆ¶åˆ° target_base_path/image å’Œ target_base_path/maskã€‚
    """
    training_path = training_dir
    image_target = osp.join(target_base_path, "image")
    mask_target = osp.join(target_base_path, "mask")

    # åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹
    if not os.path.exists(image_target):
        os.makedirs(image_target)
    if not os.path.exists(mask_target):
        os.makedirs(mask_target)

    # éå† training æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for filename in os.listdir(training_dir):
        file_path = os.path.join(training_dir, filename)

        if not os.path.isfile(file_path):
            continue  # è·³è¿‡å­ç›®å½•ç­‰éæ–‡ä»¶é¡¹

        # åˆ†ç¦»æ–‡ä»¶åå’Œåç¼€
        name, ext = os.path.splitext(filename)  # name æ˜¯ä¸å«åç¼€çš„æ–‡ä»¶å

        # åˆ¤æ–­æ˜¯å¦ä»¥ _1 æˆ– _2 ç»“å°¾
        if name.endswith('_1'):
            # å›¾åƒæ–‡ä»¶ï¼Œå»æ‰æœ«å°¾ '_1'
            new_name = name[:-2] + ext  # å»æ‰æœ€åä¸¤ä¸ªå­—ç¬¦ '_1'
            dest = os.path.join(image_target, new_name)
            shutil.copy2(file_path, dest)
            # print(f"ğŸ–¼ï¸  Copied image: {filename} -> {new_name} in 'image'")

        elif name.endswith('_2'):
            # æ ‡ç­¾æ–‡ä»¶ï¼Œå»æ‰æœ«å°¾ '_2'
            new_name = name[:-2] + ext  # å»æ‰æœ€åä¸¤ä¸ªå­—ç¬¦ '_2'
            dest = os.path.join(mask_target, new_name)
            shutil.copy2(file_path, dest)
            # print(f"ğŸŸ¥ Copied mask:  {filename} -> {new_name} in 'mask'")

        else:
            continue  # è·³è¿‡ä¸ç¬¦åˆè§„åˆ™çš„æ–‡ä»¶

    # print("âœ… æ•°æ®é›†æ•´ç†å¹¶é‡å‘½åå®Œæˆï¼")

def __generate_and_save_point_labels(
    dataset_class: NUDTDataset,
    base_dir: str,
    output_dir: str,
    base_size: int = 256,
):
    """
    ç”Ÿæˆ offset=0 çš„ç‚¹æ ‡ç­¾ï¼Œå¹¶ä¿å­˜ä¸ºä¸åŸå›¾åŒåçš„ PNG æ–‡ä»¶ã€‚
    
    Args:
        base_dir (str): NUDT æ•°æ®é›†æ ¹ç›®å½•ï¼Œå¦‚ "W:/DataSets/Infraid_datasets/NUDT-SIRST"
        output_dir (str): ç‚¹æ ‡ç­¾ä¿å­˜è·¯å¾„
        base_size (int): è¾“å…¥å°ºå¯¸
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # åˆå§‹åŒ– datasetï¼Œå¯ç”¨ pt_label ä¸” offset=0
    dataset = dataset_class(
        base_dir=base_dir,
        mode="train",
        base_size=base_size,
        pt_label=True,      # å¯ç”¨ç‚¹æ ‡ç­¾ç”Ÿæˆ
        offset=0,           # 0åç§»
        pseudo_label=False,
        preded_label=False,
        augment=False,      # ä¸è¦æ•°æ®å¢å¼ºï¼Œå¦åˆ™ç‚¹ä½ç½®ä¼šå˜
    )

    print(f"å…± {len(dataset)} å¼ å›¾åƒå¾…å¤„ç†...")

    for i in range(len(dataset)):
        name = dataset.names[i]
        img, mask_with_pt = dataset[i]  # mask_with_pt[0] æ˜¯ç‚¹æ ‡ç­¾

        # æå–ç‚¹æ ‡ç­¾ï¼ˆç¬¬ä¸€ä¸ªé€šé“ï¼‰
        pt_label = mask_with_pt[0]  # shape: [H, W], å€¼ä¸º 0 æˆ– 1ï¼ˆå› ä¸º /255.0 äº†ï¼‰

        # è½¬å› 0-255 çš„ uint8 æ ¼å¼
        pt_label_np = (pt_label * 255).byte().cpu().numpy()

        # ä¿å­˜è·¯å¾„
        save_path = os.path.join(output_dir, name)
        cv2.imwrite(save_path, pt_label_np)

        if (i + 1) % 50 == 0:
            print(f"å·²å¤„ç† {i + 1}/{len(dataset)}")

    print(f"âœ… æ‰€æœ‰ç‚¹æ ‡ç­¾å·²ä¿å­˜è‡³: {output_dir}")

def __resize_and_save_dataset(
    dataset_class: NUDTDataset,
    src_base_dir: str,
    dst_base_dir: str,
    base_size: int = 256
):
    """
    å°† NUDT æ•°æ®é›†çš„ trainval å’Œ test çš„ images/masks resize åˆ° base_sizeï¼Œå¹¶ä¿å­˜åˆ°æ–°ç›®å½•ã€‚
    
    ç›®å½•ç»“æ„ç¤ºä¾‹ï¼š
    dst_base_dir/
        â”œâ”€â”€ trainval/
        â”‚   â”œâ”€â”€ images/
        â”‚   â””â”€â”€ masks/
        â””â”€â”€ test/
            â”œâ”€â”€ images/
            â””â”€â”€ masks/
    """
    # for mode in ["train", "test"]:
    for mode in ["train"]:
        print(f"\nğŸ”„ æ­£åœ¨å¤„ç† {mode} é›†...")

        # åˆ›å»ºç›®æ ‡ç›®å½•
        if mode == "train":
            dst_img_dir = os.path.join(dst_base_dir, "trainval", "images")
            dst_mask_dir = os.path.join(dst_base_dir, "trainval", "masks")
        else:
            dst_img_dir = os.path.join(dst_base_dir, "test", "images")
            dst_mask_dir = os.path.join(dst_base_dir, "test", "masks")
        
        os.makedirs(dst_img_dir, exist_ok=True)
        os.makedirs(dst_mask_dir, exist_ok=True)

        # åˆå§‹åŒ– datasetï¼Œå¯ç”¨ pt_label ä¸” offset=0
        dataset = dataset_class(base_dir=src_base_dir,
                                mode=mode,
                                base_size=base_size,
                                pt_label=False,      # å¯ç”¨ç‚¹æ ‡ç­¾ç”Ÿæˆ
                                offset=0,           # 0åç§»
                                pseudo_label=False,
                                preded_label=False,
                                augment=False,      # ä¸è¦æ•°æ®å¢å¼ºï¼Œå¦åˆ™ç‚¹ä½ç½®ä¼šå˜
                                )

        print(f"å…± {len(dataset)} å¼ å›¾åƒå¾…å¤„ç†...")

        for i in range(len(dataset)):
            name = dataset.names[i]
            img, mask = dataset[i]  # img: [1, H, W], mask: [1, H, W] (å€¼ä¸º 0~1)

            mask = (mask.float() > 0.5).float()

            # è½¬ä¸º numpy uint8 (0-255)
            img_np = (img.squeeze(0).cpu().numpy() * 255).astype('uint8')
            mask_np = (mask.squeeze(0).cpu().numpy() * 255).astype('uint8')

            # ä¿å­˜
            cv2.imwrite(os.path.join(dst_img_dir, name), img_np)
            cv2.imwrite(os.path.join(dst_mask_dir, name), mask_np)

            if (i + 1) % 50 == 0:
                print(f"  å·²å¤„ç† {i + 1}/{len(dataset)}")

    print(f"\nâœ… å…¨éƒ¨æ•°æ®å·²ä¿å­˜è‡³: {dst_base_dir}")


def __split_dataset_by_index_with_mask_prefix_match(root_dir: str):
    """
    æ ¹æ® images æ–‡ä»¶åï¼Œåœ¨ masks ä¸­æŸ¥æ‰¾å‰ç¼€åŒ¹é…çš„æ–‡ä»¶ï¼ˆå¦‚ Misc_25.png â†” Misc_25_pixels0.pngï¼‰ï¼Œ
    æŒ‰ç´¢å¼•å¥‡å¶åˆ’åˆ†ï¼Œå¹¶å°† mask é‡å‘½åä¸ºä¸ image ä¸€è‡´ã€‚
    
    è¦æ±‚ï¼š
      - images/ ä¸‹: Misc_25.png
      - masks/  ä¸‹: Misc_25_pixels0.png, Misc_25_pixels1.png ç­‰ï¼ˆä½†åº”åªå­˜åœ¨ä¸€ä¸ªåŒ¹é…é¡¹ï¼‰
    """
    root = Path(root_dir)
    img_dir = root / "images"
    mask_dir = root / "masks"

    if not (img_dir.exists() and mask_dir.exists()):
        raise FileNotFoundError(f"è¯·ç¡®ä¿ {root} ä¸‹å­˜åœ¨ 'images' å’Œ 'masks' æ–‡ä»¶å¤¹ï¼")

    # è·å–æ‰€æœ‰ image æ–‡ä»¶ï¼ˆ.pngï¼‰ï¼Œæ’åº
    image_files = sorted([f for f in img_dir.glob("*.png")], key=lambda x: x.name)
    if not image_files:
        raise ValueError("images æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰ .png æ–‡ä»¶ï¼")

    # æ„å»º mask æ–‡ä»¶åæ˜ å°„ï¼šmask_stem -> full_path
    # ä¾‹å¦‚ï¼š "Misc_25" -> Path("masks/Misc_25_pixels0.png")
    mask_files = list(mask_dir.glob("*.png"))
    mask_stem_to_path = {}
    for mf in mask_files:
        # å»æ‰æ‰€æœ‰å¯èƒ½çš„åç¼€å˜ä½“ï¼Œåªä¿ç•™ä¸»å¹²ï¼ˆå¦‚ "Misc_25_pixels0" -> å°è¯•åŒ¹é… "Misc_25"ï¼‰
        # ç­–ç•¥ï¼šä»åå¾€å‰å°è¯•å»æ‰ "_pixels..." ç­‰éƒ¨åˆ†
        stem = mf.stem
        # ç®€å•ç­–ç•¥ï¼šå¦‚æœåŒ…å« "_pixels"ï¼Œåˆ™æˆªæ–­
        if "_pixels" in stem:
            base_stem = stem.split("_pixels")[0]
        else:
            # å¦åˆ™å°è¯•é€šç”¨æ–¹å¼ï¼šä¿ç•™ä¸»å¹²ï¼ˆå¯æ ¹æ®å®é™…å‘½åè°ƒæ•´ï¼‰
            base_stem = stem
        # ä¹Ÿå¯ä»¥æ›´é€šç”¨ï¼šå‡è®¾ image çš„ stem å°±æ˜¯ mask stem çš„å‰ç¼€
        mask_stem_to_path[stem] = mf  # å…ˆä¿ç•™åŸå§‹ stem åˆ°è·¯å¾„

    # é…å¯¹åˆ—è¡¨ï¼š[(img_path, mask_path), ...]
    paired_files = []
    for img_path in image_files:
        img_stem = img_path.stem  # e.g., "Misc_25"
        img_name = img_path.name  # e.g., "Misc_25.png"

        # åœ¨ mask ä¸­æŸ¥æ‰¾ï¼šæ˜¯å¦æœ‰ mask æ–‡ä»¶çš„ stem ä»¥ img_stem å¼€å¤´ï¼Ÿ
        matched_masks = []
        for mask_stem, mask_path in mask_stem_to_path.items():
            if mask_stem.startswith(img_stem):
                # è¿›ä¸€æ­¥ç¡®ä¿ä¸æ˜¯è¯¯åŒ¹é…ï¼ˆæ¯”å¦‚ Misc_25 ä¸åŒ¹é… Misc_250ï¼‰
                # è¦æ±‚ï¼šmask_stem == img_stem æˆ– mask_stem == img_stem + "_pixelsX"
                if mask_stem == img_stem or mask_stem.startswith(img_stem + "_"):
                    matched_masks.append(mask_path)

        if len(matched_masks) == 0:
            print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°ä¸ {img_name} åŒ¹é…çš„ mask æ–‡ä»¶ï¼Œè·³è¿‡ã€‚")
            continue
        elif len(matched_masks) > 1:
            print(f"âš ï¸ è­¦å‘Š: æ‰¾åˆ°å¤šä¸ª mask åŒ¹é… {img_name}ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª: {[m.name for m in matched_masks]}")
        
        mask_path = matched_masks[0]
        paired_files.append((img_path, mask_path))

    if not paired_files:
        raise ValueError("æœªæ‰¾åˆ°ä»»ä½• image-mask é…å¯¹ï¼")

    print(f"å…±é…å¯¹ {len(paired_files)} å¯¹å›¾åƒä¸æ ‡ç­¾ã€‚")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    for split in ["trainval", "test"]:
        (root / split / "images").mkdir(parents=True, exist_ok=True)
        (root / split / "masks").mkdir(parents=True, exist_ok=True)

    # æŒ‰ç´¢å¼•å¥‡å¶åˆ’åˆ†
    for idx, (img_path, mask_path) in enumerate(paired_files):
        target_split = "trainval" if idx % 2 == 0 else "test"
        target_img_dir = root / target_split / "images"
        target_mask_dir = root / target_split / "masks"

        # å¤åˆ¶ imageï¼ˆä¿æŒåŸåï¼‰
        shutil.copy2(img_path, target_img_dir / img_path.name)

        # å¤åˆ¶ maskï¼Œä½†**é‡å‘½åä¸º image çš„æ–‡ä»¶å**
        new_mask_name = img_path.name  # å…³é”®ï¼šè®© mask å’Œ image åŒå
        shutil.copy2(mask_path, target_mask_dir / new_mask_name)

    print(f"âœ… åˆ’åˆ†å®Œæˆï¼")
    print(f"   trainval: {len(paired_files[::2])} å¯¹")
    print(f"   test:     {len(paired_files[1::2])} å¯¹")


if __name__ == "__main__":
    # TRAINING_DIR = "W:/DataSets/ISTD/MDvsFA_cGAN-master/data/training"   # åŸå§‹æ–‡ä»¶å¤¹è·¯å¾„
    TARGET_PATH = "W:/DataSets/ISTD/SIRST"        # ç›®æ ‡æ ¹è·¯å¾„
    # SIRST_PATH = "W:/DataSets/ISTD/SIRST"
    # base_dir = "W:/DataSets/ISTD/NUDT-SIRST"
    # base_dir = "W:/DataSets/ISTD/IRSTD-1k"
    # pt_label_dir =  base_dir + "/trainval/point_label"

    # __split_dataset_by_index_with_mask_prefix_match(SIRST_PATH)
    # __organize_dataset(TRAINING_DIR, TARGET_PATH)
    # __generate_and_save_point_labels(IRSTD1kDataset, base_dir, pt_label_dir, 512)
    __resize_and_save_dataset(MDFADataset, TARGET_PATH, TARGET_PATH, 256)