{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e7805de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.ndimage\n",
    "\n",
    "def mask2point_n(mask, offset=3):\n",
    "    # 将mask和img转换为numpy数组\n",
    "    base_size = mask.shape[-1]\n",
    "    mask_array = np.array(mask.cpu())  # 假设mask是tensor类型\n",
    "\n",
    "    # 使用连通组件分析找到所有独立的目标区域\n",
    "    labels, num_features = scipy.ndimage.label(mask_array > 0.1)\n",
    "\n",
    "    pts_label = torch.zeros_like(mask, dtype=torch.float32)\n",
    "\n",
    "    for label_id in range(1, num_features + 1):\n",
    "        target_mask = labels == label_id\n",
    "        coords = np.argwhere(target_mask)\n",
    "\n",
    "        if len(coords) == 0:\n",
    "            continue\n",
    "\n",
    "        masked_coords = coords\n",
    "\n",
    "        # 计算原质心\n",
    "        centroid = np.mean(coords, axis=0).astype(np.int64)\n",
    "        if target_mask[centroid[0], centroid[1]] == 0:\n",
    "            corrd_diff = coords - centroid\n",
    "            min_dist_idx = np.argmin(np.sum(corrd_diff**2, axis=1))\n",
    "            centroid = coords[min_dist_idx]\n",
    "\n",
    "        # 找到离质心最近的亮点\n",
    "        dists = np.linalg.norm(masked_coords - centroid, axis=1)\n",
    "        nearest_point = masked_coords[np.argmin(dists)]\n",
    "        if nearest_point.ndim > 1:\n",
    "            nearest_point = nearest_point[0]\n",
    "\n",
    "        point_y_x = nearest_point.copy()\n",
    "\n",
    "        # 偏移：沿随机方向偏移固定距离 offset\n",
    "        if offset > 0:\n",
    "            theta = np.random.uniform(0, 2 * np.pi)\n",
    "            # 注意坐标顺序：point_y_x = [y, x]\n",
    "            ideal_y = point_y_x[0] + offset * np.sin(theta)\n",
    "            ideal_x = point_y_x[1] + offset * np.cos(theta)\n",
    "            ideal_point = np.array([ideal_y, ideal_x])\n",
    "\n",
    "            # 限制在图像范围内（防止无效坐标）\n",
    "            ideal_point = np.clip(ideal_point, 0, base_size - 1)\n",
    "\n",
    "            # 在当前连通区域中找离 ideal_point 最近的前景点\n",
    "            dists = np.linalg.norm(masked_coords - ideal_point, axis=1)\n",
    "            nearest_point_candidate = masked_coords[np.argmin(dists)]\n",
    "\n",
    "            # 仅当找到不同的点时才更新\n",
    "            if not np.array_equal(nearest_point_candidate, point_y_x):\n",
    "                point_y_x = nearest_point_candidate\n",
    "\n",
    "        # 设置最终的点标签\n",
    "        pts_label[point_y_x[0], point_y_x[1]] = 1.\n",
    "\n",
    "    return pts_label\n",
    "\n",
    "def mask2point(mask, img, offset=3):\n",
    "    # 将mask和img转换为numpy数组\n",
    "    base_size = mask.shape[-1]\n",
    "    mask_array = np.array(mask.cpu())  # 假设mask是tensor类型\n",
    "    img_array = np.array(img.cpu())  # H x W x C 格式\n",
    "\n",
    "    # 使用连通组件分析找到所有独立的目标区域\n",
    "    labels, num_features = scipy.ndimage.label(mask_array > 0.9)\n",
    "\n",
    "    pts_label = torch.zeros_like(mask, dtype=torch.float32)\n",
    "\n",
    "    for label_id in range(1, num_features + 1):\n",
    "        target_mask = labels == label_id\n",
    "        coords = np.argwhere(target_mask)\n",
    "\n",
    "        if len(coords) == 0:\n",
    "            continue\n",
    "\n",
    "        # 获取目标区域内的图像像素值及其坐标\n",
    "        masked_img_vals = img_array[target_mask]\n",
    "        # print(masked_img_vals.shape)\n",
    "        masked_coords = coords\n",
    "\n",
    "        # 计算每个像素的亮度（例如灰度值）\n",
    "        brightness = masked_img_vals.flatten()\n",
    "\n",
    "        # 找出最亮部分的像素\n",
    "        threshold = np.percentile(brightness, 50)\n",
    "        bright_coords = masked_coords[brightness >= threshold]\n",
    "\n",
    "        # 如果没有亮点，跳过\n",
    "        if len(bright_coords) == 0:\n",
    "            continue\n",
    "\n",
    "        # 计算原质心\n",
    "        centroid = np.mean(coords, axis=0).astype(np.int64)\n",
    "        if target_mask[centroid[0], centroid[1]] == 0:\n",
    "            corrd_diff = coords - centroid\n",
    "            min_dist_idx = np.argmin(np.sum(corrd_diff**2, axis=1))\n",
    "            centroid = coords[min_dist_idx]\n",
    "\n",
    "        # 找到离质心最近的亮点\n",
    "        dists = np.linalg.norm(bright_coords - centroid, axis=1)\n",
    "        nearest_point = bright_coords[np.argmin(dists)]\n",
    "        if nearest_point.ndim > 1:\n",
    "            nearest_point = nearest_point[0]\n",
    "\n",
    "        point_y_x = nearest_point.copy()\n",
    "\n",
    "        # 偏移：沿随机方向偏移固定距离 offset\n",
    "        if offset > 0:\n",
    "            theta = np.random.uniform(0, 2 * np.pi)\n",
    "            # 注意坐标顺序：point_y_x = [y, x]\n",
    "            ideal_y = point_y_x[0] + offset * np.sin(theta)\n",
    "            ideal_x = point_y_x[1] + offset * np.cos(theta)\n",
    "            ideal_point = np.array([ideal_y, ideal_x])\n",
    "\n",
    "            # 限制在图像范围内（防止无效坐标）\n",
    "            ideal_point = np.clip(ideal_point, 0, base_size - 1)\n",
    "\n",
    "            # 在当前连通区域中找离 ideal_point 最近的前景点\n",
    "            dists = np.linalg.norm(bright_coords - ideal_point, axis=1)\n",
    "            nearest_point_candidate = bright_coords[np.argmin(dists)]\n",
    "\n",
    "            # 仅当找到不同的点时才更新\n",
    "            if not np.array_equal(nearest_point_candidate, point_y_x):\n",
    "                point_y_x = nearest_point_candidate\n",
    "\n",
    "        # 设置最终的点标签\n",
    "        pts_label[point_y_x[0], point_y_x[1]] = 1.\n",
    "\n",
    "    return pts_label\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def proper_region_square(pred, c1, c2, extend_factor=0.5, initial_size=64, mini_size=6, max_size=64):\n",
    "    H, W = pred.shape\n",
    "    assert 0 <= c1 < H and 0 <= c2 < W, f\"Center ({c1}, {c2}) out of image bounds [{H}, {W}]\"\n",
    "\n",
    "    half_search = initial_size // 2\n",
    "    min_step = mini_size // 2\n",
    "\n",
    "    pred_padded = F.pad(pred, (half_search, half_search, half_search, half_search), value=0.0)\n",
    "    pad_offset = half_search\n",
    "    center_r = c1 + pad_offset\n",
    "    center_c = c2 + pad_offset\n",
    "\n",
    "    def find_boundary(center, axis, direction, other_slice):\n",
    "        boundary = center + direction * half_search\n",
    "        for i in range(min_step, half_search + 1):\n",
    "            pos = center + direction * i\n",
    "            if axis == 0:  # row-wise (top/bottom)\n",
    "                start_row = max(0, pos - 1)\n",
    "                end_row = min(pred_padded.shape[0], pos + 2)\n",
    "                val = torch.sum(pred_padded[start_row:end_row, other_slice])\n",
    "            else:  # col-wise (left/right)\n",
    "                start_col = max(0, pos - 1)\n",
    "                end_col = min(pred_padded.shape[1], pos + 2)\n",
    "                val = torch.sum(pred_padded[other_slice, start_col:end_col])\n",
    "            if val < 1.0:\n",
    "                boundary = center + direction * (i - 1)\n",
    "                break\n",
    "        return boundary\n",
    "\n",
    "    # Step 1: Get original bounding box\n",
    "    init_col_slice = slice(center_c - half_search, center_c + half_search)\n",
    "    top = find_boundary(center_r, axis=0, direction=-1, other_slice=init_col_slice)\n",
    "    bottom = find_boundary(center_r, axis=0, direction=+1, other_slice=init_col_slice) + 1\n",
    "\n",
    "    row_slice = slice(top, bottom)\n",
    "    left = find_boundary(center_c, axis=1, direction=-1, other_slice=row_slice)\n",
    "    right = find_boundary(center_c, axis=1, direction=+1, other_slice=row_slice) + 1\n",
    "\n",
    "    # Convert back to original coordinates\n",
    "    top_orig = max(0, top - pad_offset)\n",
    "    bottom_orig = min(H, bottom - pad_offset)\n",
    "    left_orig = max(0, left - pad_offset)\n",
    "    right_orig = min(W, right - pad_offset)\n",
    "\n",
    "    # Step 2: Compute minimal square radius that covers the box around (c1, c2)\n",
    "    r_up = c1 - top_orig\n",
    "    r_down = bottom_orig - c1\n",
    "    r_left = c2 - left_orig\n",
    "    r_right = right_orig - c2\n",
    "\n",
    "    # The minimal radius to cover all sides\n",
    "    r = max(r_up, r_down, r_left, r_right)\n",
    "\n",
    "    # Apply extension\n",
    "    r_extended = r * (1.0 + extend_factor)\n",
    "    r_extended = max(r_extended, 1.0)  # at least 1\n",
    "\n",
    "    # Limit by max_size\n",
    "    max_radius = max_size // 2\n",
    "    r_final = min(r_extended, max_radius)\n",
    "\n",
    "    # Step 3: Build square region centered at (c1, c2)\n",
    "    s1 = int(c1 - r_final)\n",
    "    e1 = int(c1 + r_final)\n",
    "    s2 = int(c2 - r_final)\n",
    "    e2 = int(c2 + r_final)\n",
    "\n",
    "    # Ensure within safe margins [1, H-2], [1, W-2]\n",
    "    s1 = max(1, s1)\n",
    "    e1 = min(H - 2, e1)\n",
    "    s2 = max(1, s2)\n",
    "    e2 = min(W - 2, e2)\n",
    "\n",
    "    # Final safety: ensure non-empty\n",
    "    if s1 >= e1:\n",
    "        s1, e1 = max(1, c1 - 1), min(H - 2, c1 + 2)\n",
    "    if s2 >= e2:\n",
    "        s2, e2 = max(1, c2 - 1), min(W - 2, c2 + 2)\n",
    "\n",
    "    return int(s1), int(e1), int(s2), int(e2)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# ========== 你已有的代码（略作整理）==========\n",
    "img_path = \"W:/DataSets/ISTD/NUDT-SIRST/trainval/images_target\"\n",
    "mask_path = \"W:/DataSets/ISTD/NUDT-SIRST/trainval/masks\"\n",
    "\n",
    "names = os.listdir(img_path)\n",
    "\n",
    "masks = []\n",
    "pt_labels = []\n",
    "\n",
    "for name in names[:20]:  # 只取前8个样本用于绘图（避免太多）\n",
    "    img = cv2.imread(os.path.join(img_path, name), 0)\n",
    "    mask = cv2.imread(os.path.join(mask_path, name), 0)\n",
    "\n",
    "    if img is None or mask is None:\n",
    "        continue\n",
    "\n",
    "    # ones = np.ones_like(img)\n",
    "    # ones_torch = torch.from_numpy(ones)\n",
    "\n",
    "    mask_torch = torch.from_numpy(mask).float()\n",
    "    img_torch = torch.from_numpy(img).float()\n",
    "\n",
    "    pt0_label = mask2point(mask_torch, img_torch, 0).numpy()\n",
    "    pt3_label = mask2point(mask_torch, img_torch, 3).numpy()\n",
    "    pt10_label = mask2point(mask_torch, img_torch, 10).numpy()\n",
    "\n",
    "    indices = np.nonzero(pt0_label)\n",
    "\n",
    "    # 裁剪区域\n",
    "    coors = proper_region_square(mask_torch, indices[0][0], indices[1][0], 0.5)  # 注意：这里应该是 indices[1] 而不是 indices[0] 第二次！\n",
    "    cropped_mask = mask[coors[0]:coors[1], coors[2]:coors[3]]\n",
    "    cropped_pt0 = pt0_label[coors[0]:coors[1], coors[2]:coors[3]]\n",
    "    cropped_pt3 = pt3_label[coors[0]:coors[1], coors[2]:coors[3]]\n",
    "    cropped_pt10 = pt10_label[coors[0]:coors[1], coors[2]:coors[3]]\n",
    "\n",
    "    masks.append(cropped_mask)\n",
    "    pt_labels.append(np.stack([cropped_pt0, cropped_pt3, cropped_pt10], axis=0))\n",
    "\n",
    "# 确保有至少8个样本\n",
    "if len(masks) < 8:\n",
    "    raise ValueError(f\"Only {len(masks)} valid samples found, need at least 8.\")\n",
    "\n",
    "# ========== 新增：提取点坐标并绘图 ==========\n",
    "point_coords_list = []  # 将存储 (8, 3, 2) 的坐标，若某类无点则跳过或设为 None\n",
    "\n",
    "for i in range(8):\n",
    "    mask_h, mask_w = masks[i].shape\n",
    "    coords_per_sample = []\n",
    "    for j in range(3):  # 三种点标签\n",
    "        pt_map = pt_labels[i][j]\n",
    "        pts = np.argwhere(pt_map == 1)  # shape: (N, 2), each is [row, col]\n",
    "        if len(pts) > 0:\n",
    "            # 取第一个点（假设每类只有一个点，符合你原始 (8,3,1,1) 设定）\n",
    "            coord = pts[0]  # [row, col]\n",
    "        else:\n",
    "            # 如果没有点，可以设为图像中心或跳过绘制\n",
    "            coord = np.array([mask_h // 2, mask_w // 2])  # fallback\n",
    "        coords_per_sample.append(coord)\n",
    "    point_coords_list.append(np.stack(coords_per_sample, axis=0))  # (3, 2)\n",
    "\n",
    "# 转为 numpy array: (8, 3, 2)\n",
    "point_coords = np.stack(point_coords_list, axis=0)\n",
    "\n",
    "# ========== 绘图：将点位置的像素直接染成红、绿、蓝 ==========\n",
    "colors_rgb = [\n",
    "    [255, 0, 0],     # 红色 (R)\n",
    "    [0, 255, 0],     # 绿色 (G)\n",
    "    [0, 0, 255]      # 蓝色 (B)\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(8):\n",
    "    ax = axes[i]\n",
    "    mask_gray = masks[i]  # shape: (H, W), uint8 or float\n",
    "    \n",
    "    # 转为 RGB 图像：先复制灰度图到三通道\n",
    "    if mask_gray.dtype == np.bool_:\n",
    "        mask_gray = mask_gray.astype(np.uint8) * 255\n",
    "    elif mask_gray.max() <= 1.0 and mask_gray.dtype != np.uint8:\n",
    "        mask_gray = (mask_gray * 255).astype(np.uint8)\n",
    "    elif mask_gray.dtype != np.uint8:\n",
    "        mask_gray = mask_gray.astype(np.uint8)\n",
    "    \n",
    "    # 创建 RGB 图像\n",
    "    mask_rgb = np.stack([mask_gray, mask_gray, mask_gray], axis=-1)  # (H, W, 3)\n",
    "\n",
    "    # 获取三种点的坐标\n",
    "    for j in range(3):\n",
    "        row, col = point_coords[i, j]\n",
    "        # 确保坐标在图像范围内\n",
    "        if 0 <= row < mask_rgb.shape[0] and 0 <= col < mask_rgb.shape[1]:\n",
    "            mask_rgb[row, col] = colors_rgb[j]  # 直接修改该像素为对应颜色\n",
    "\n",
    "    ax.imshow(mask_rgb)\n",
    "    # ax.set_title(names[i], fontsize=12)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout(pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c2947e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发现轮廓，面积 = 2178990 像素\n",
      "\n",
      "✅ 最终检测到零件数量: 1\n",
      "结果已保存为 'result.jpg'（带绿框）和 'binary.jpg'（黑白图）\n"
     ]
    }
   ],
   "source": [
    "# 文件名：contour_demo.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 尝试读取一张真实图片（比如你手机拍的几个瓶盖）\n",
    "img = cv2.imread(\"20251024231821.jpg\")  # ← 把 'your_image.jpg' 换成你的图片路径\n",
    "\n",
    "# 1. 转灰度\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 2. 二值化（黑白图）\n",
    "_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# 3. 找轮廓（只取最外层）\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# 4. 分析每个轮廓\n",
    "count = 0\n",
    "for cnt in contours:\n",
    "    area = cv2.contourArea(cnt)\n",
    "    print(f\"发现轮廓，面积 = {area:.0f} 像素\")\n",
    "    if area > 1000:  # 过滤掉小噪声（比如那个5x5=25像素的小点）\n",
    "        count += 1\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)  # 画绿框\n",
    "\n",
    "print(f\"\\n✅ 最终检测到零件数量: {count}\")\n",
    "\n",
    "# 保存结果（无需弹窗，适合所有环境）\n",
    "cv2.imwrite('result.jpg', img)\n",
    "cv2.imwrite('binary.jpg', thresh)\n",
    "print(\"结果已保存为 'result.jpg'（带绿框）和 'binary.jpg'（黑白图）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bbcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
